\section{序論}
\label{sec:intro}
\subsection{背景と目的}
近年，GoPro\footnote{https://gopro.com}やGoogle Glass\footnote{https://www.google.com/glass}といったカメラ機能のついた様々なウェアラブルデバイスの普及に伴い，
カメラの装着者から見た視界を記録した一人称視点映像が盛んに利用されている(図\ref{fig:intro-fpv}).
一人称視点映像の中では，映像の観測者の視界に別の人物が映り込む場合がある，
このような映像を二人称視点映像と呼ぶ(図\ref{fig:intro-second-person-view})．
二人称視点映像中では，定点カメラなどの三人称視点映像と比べて対象が大きく映り込むことにより，対象の手元の動きなどの細かい情報を捉えることができる．

この二人称視点映像を利用することにより，人物同士のやり取りの検出や人間関係の推定する研究が行われてきた\cite{alletto2014_383, FathiHR12}．
検出された動作が頷きであるのか，首をかしげる動作であるのかといった動作種類の認識を行うことができれば，そのやり取りがポジティブな意思表示によるものなのかネガティブな意思表示によるものなのかといったより詳細な分析を得ることができる．

そこで，本研究では特に映像の記録者と他者が会話をしている状況をとりあげ，二人称視点映像からやり取りの中で生じる``呼びかけ"や``顔向け"といった動作を認識する問題に取り組む． 
文献\cite{wang2011, TDD}に見られるように，動作認識に関する従来手法の多くではまず画面全体からhistograms of oriented optical flow(HOOF)\cite{HOGHOF}やhistogram of oriented gradients(HoG)\cite{HOG}といった局所特徴量を抽出し，
それらをbag of features\cite{BOF_1, BOF_2}やFisher vector\cite{fisher_vector}といったコーディング手法によって処理することで映像全体を表す高次特徴を生成するというアプローチを取る．

しかしながら，二人称視点映像を用いる本研究においては，カメラ装着者の頭部運動によって引き起こされる映像背景の動きが局所特徴群に含まれ，高次特徴の生成に影響を及ぼす可能性がある．
また，今回取り扱うような二人称視点映像の記録者と他者との間のやり取りによる動作映像では，同映像中に複数人物が現れる場合にやり取りの相手である人物の動きのみを考慮した高次特徴を生成する方が好ましいと考えられる．
本研究では，これらの問題を解決するために映像全体から生成された局所特徴群の中で動作認識において重要なものを推定しつつ高次特徴を生成するというアプローチを考える．

このような中，近年ユーザーの視線方向を計測する視線計測機器が従来より安価かつ手軽に利用できるようになった．
特にPupil Pro\footnote{https://pupil-labs.com}などのウェアラブルカメラと一体になった視線計測機器を用いることにより，一人称視点映像中でのカメラ装着者の視線位置を計測することが可能である．
このような情報は，映像の記録者がどのような場所に注意を向けているのかといった情報を知る手がかりになる．

そこで本研究では，このようなデバイスで計測された二人称視点映像中の視線位置を用いることで映像中のどの部位に現れる局所特徴が重要であるかを推定するアプローチを提案する．
本研究で取り上げるような会話のやり取りの中では，やり取りの相手の人間の動きに映像の記録者の視線が向けられることが期待される．
そのため，視線位置の周囲に現れる局所特徴を重要であるとみなすことで重要な局所特徴を推定することができ，上記の背景運動や複数人物の映り込みといった問題を解決することができる．
提案手法では，視線位置からある一定の距離の範囲内値から生成された局所特徴を動作認識に有用な局所特徴とし，これらの局所特徴のみを用いて高次特徴を生成することで動作を認識する(図\ref{fig:intro_filtered_traj})．

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{images/intro-fpv.ai}
\caption[一人称視点カメラの例]{一人称視点カメラの例 \protect \footnotemark}
\label{fig:intro-fpv}
\end{center}
\end{figure}
\footnotetext{https://www.google.com/glass, https://gopro.com, http://news.panasonic.com/jp/topics/2015/38838.html}

\begin{figure}
\begin{center}
\includegraphics[width=14cm]{images/intro-second-person-view.ai}
\caption[二人称視点映像の例]{
    二人称映像の例．
    このような映像が映像記録者の頭部に装着された一人称視点カメラにより収録される．
    本研究では，``呼びかけ"や``挙手"といった映像記録者と相手の間でのやり取りの中で発生する動作の映像を取り扱った．
    }
\label{fig:intro-second-person-view}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=14cm]{images/intro_filtered_traj.ai}
\caption[視線情報を元にした局所特徴選択の例]
    {視線情報を元にした局所特徴選択の例．
    緑色の線はdense trajectories\cite{IDT}という，映像中の特徴点の軌跡を可視化したものである．
    左列は選択される前の全局所特徴に対応するdense trajectoriesを，右列は視線情報をもとに選択されたdense trajectoriesを可視化している．
    右列では視線位置を黄色の丸で示した．
    }
    \label{fig:intro_filtered_traj}
\end{center}
\end{figure}

本研究の貢献は以下の通りである．

\begin{itemize}
    \item 二人称視点映像における映像記録者の視線を利用した動作認識手法を開発した．
    \item 提案手法の評価のために，映像記録者の視線情報を記録した二人称視点映像データセットを作成し，視線を利用した動作認識手法の評価を可能にした．
          収録したデータセットは6人の被験者による12種類の動作により構成され，全体で約1300サンプルの動作映像を含む．
    \item 構築したデータセットを用いて，視線を利用した動作認識手法と視線を利用しない動作認識手法を比較した．
          結果として，二人称視点映像中の対話動作の認識における視線利用の有用性を確認した．
\end{itemize}

\subsection{論文の構成}

本論文は全7章で構成され，視線情報を利用した二人称視点動作認識の手法を提案しその有用性を検証するものである．

第\ref{sec:intro}章では，序論として本研究の目的と背景について述べた．
第\ref{sec:related}章では，本研究の関連研究として一人称視点映像や動作認識，視線情報を扱った研究を紹介する．
第\ref{sec:method}章では，視線位置を加味した二人称視点映像動作認識手法を提案し，その詳細を説明する．
第\ref{sec:implementation}章では，提案手法の実装の詳細として具体的なパラメタや細かい手法について説明する．
第\ref{sec:dataset}章では，提案手法の評価を目的として収録した視線情報付きの二人称視点映像データセットについて説明する．
第\ref{sec:experiment}章では，提案手法の評価のために行った実験の概要と結果について説明する．
第\ref{sec:conclusion}章では，本研究の結論と今後の展望について述べる．

\newpage



