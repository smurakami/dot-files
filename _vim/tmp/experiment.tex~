\section{実験}
\label{sec:experiment}

\subsection{実験概要}

本研究では提案手法の評価のために第\ref{sec:dataset}章で作成したデータセットを用いて認識精度の評価を行った．

本研究で提案する手法は，カメラ装着者の視線情報をもとに動作映像全体に現れる局所特徴の中から動作認識において重要なものを選択し高次特徴を生成した上で認識を行う．
そのため，カメラ装着者の自発的頭部運動により現れる映像背景の動きや，複数人物の映り込みによる認識対象でない人物の動きの影響を抑えて動作認識を行うことができると考えられる．
提案手法のこのような性質を確かめるために以下の三つの手法を比較した．

\begin{itemize}
    \item GAZE: \ref{sec:method/gaze}節で論じた手法により二人称視点映像の観測者の視線周辺の局所特徴を用いて高次特徴を生成する手法(提案手法)
    \item ALL: 映像中に現れる全ての局所特徴から高次特徴を生成する手法(ベースライン)
    \item BOX: データセットに長方形であらかじめ付与した人物領域から生成された局所特徴から高次特徴を生成する手法(比較手法)
\end{itemize}

ALL は映像中に現れる全ての局所特徴から高次特徴を生成する従来手法に相当する．
それに対し提案手法である GAZE では，視線周辺の局所特徴を選択した上で用いるため ALL よりも認識精度が高くなることが期待される．
BOX は人物領域に由来する局所特徴を選択的に用いているため，理想的な局所特徴選択に近い手法である．

認識精度の評価では，6人の被験者のうち1人のサンプルをテストデータ，残りの5人のサンプルを教師データとして交差検定を行った．

\subsection{視線による局所特徴選択のための変数の決定}

第\ref{sec:method}章で論じた視線による局所特徴のための変数$(r, q)$を決定するために，$(r, q)$を様々な値に変えて精度比較を行った．
ここで最も良い精度を与えた$(r, q)$を用いて提案手法の評価を行った．

認識精度の比較の際には，12種類の動作識別の精度の平均値を評価した．
また，精度比較の際には6人の被験者のうち5人によるサンプルを教師データとしてGaussian mixture model，サポートベクタマシンの学習を行い，
残りの1人の被験者によるサンプルをテストデータとして識別対象にすることで，$(r, q)$のパラメタの算出の際に教師データとテストデータが分離するようにした．
このようなテストデータ，教師データの取り方で6人分の交差検定を実施し，その平均値を$(r, q)$のスコアとして比較を行った．

精度比較の結果を表\ref{tab:gaze_params}に示す．
結果として，$r = 60 \mathrm{ px }, q = 1 \mathrm{ pixel }$で最も精度の良い結果が得られたため，提案手法の評価に際してはこの値を採用した．

\begin{table}[h]
    \begin{center}
        \caption[各$r$, $q$に対応する GAZE の認識精度]{各$r$, $q$に対応する GAZE の認識精度}
        \label{tab:gaze_params}
        \begin{tabular}{|c||r|r|r|r|}
            \hline
            $r \backslash q$ & 1 frames & 5 frames & 10 frames & 15 frames \\ \hline \hline
            30 px & 31.3 \% & 28.2 \% & 24.7 \% & 22.4 \% \\ \hline
            60 px & \cellcolor{yellow} 37.3 \% & 36.2 \% & 32.3 \% & 29.4 \% \\ \hline
            90 px & 34.5 \% & 34.9 \% & 34.3 \% & 32.5 \% \\ \hline
            120 px & 31.0 \% & 31.1 \% & 30.0 \% & 26.9 \% \\ \hline
       \end{tabular}
    \end{center}
\end{table}

\subsection{実験結果}

GAZE，ALL，BOX の三つの手法の間での精度比較を表\ref{tb:score_mean}に示す．
本実験では12種類の動作識別の他に，手による動作種類内での識別，頭部による動作内での識別を行い，その平均スコアを比較した．
いずれの場合もGAZE が 従来手法による ALL を上回ることが確認された．
これは，視線情報を用いて重要な局所特徴を推定しつつ動作の学習及び識別を行ったため，背景や別の人物の動きの影響を軽減できたためと考えられる．
\begin{table}
\begin{center}
    \caption{各手法での認識精度比較}
    \label{tb:score_mean}
        \begin{tabular}{|c||r|r|r|}
            \hline
            & All actions & Hand actions & Head actions \\ \hline \hline
            \rowcolor{yellow} GAZE & 37.3 \% & 51.2 \% & 32.4 \% \\ \hline
            ALL & 23.6 \% & 38.1 \% &  28.0 \% \\ \hline
            BOX & 41.6 \% & 57.1 \% & 35.5 \% \\ \hline
        \end{tabular}
    \end{center}
\end{table}

\begin{figure}
\begin{center}
    \includegraphics[width=\linewidth]{images/score_action.ai}
    \caption{各動作での認識結果のf-score}
    \label{fig:score_action}
\end{center}
\end{figure}

一方，認識精度には動作種類により差が出た．
各動作種類における識別結果のf-scoreを図\ref{fig:score_action}に示す．

識別結果の大まかな傾向として，頭部による動作の識別精度が手による動作の識別精度よりも低くなることが確認された．
これは，頭部動作に含まれる動きが微細である傾向にあるため，動きの特徴を捉えきれず識別に失敗したものと思われる．
手による動作の中でも``呼びかけ"の識別精度が他と比べて低いが，これも同様の理由によるものと考えられる．

今回の実験で識別精度が高かった動作種類の例を図\ref{fig:result_good}に，識別精度の低かった動作種類の例を図\ref{fig:result_bad}に示す．

\begin{figure}
\begin{center}
    \includegraphics[width=\linewidth]{images/result_good.ai}
    \caption[識別精度の高かった動作種類の例] {
        識別精度の高かった動作種類の例．
        提案手法により選択された局所特徴に対応するdense trajectoriesと視線位置を可視化している．
        ``手を挙げる"など，大きい動きの含まれる動作種類の識別精度が高くなる傾向にあることが確認された．
        }
    \label{fig:result_good}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
    \includegraphics[width=\linewidth]{images/result_bad.ai}
    \caption[識別精度の低かった動作種類の例] {
        識別精度の低かった動作種類の例．
        提案手法により選択された局所特徴に対応するdense trajectoriesと視線位置を可視化している．
        ``頷く"など，大きい動きの含まれる動作種類の識別精度が低くなる傾向にあることが確認された．
        }
    \label{fig:result_bad}
\end{center}
\end{figure}

\subsection{考察}

本実験では GAZE, ALL, BOX の三つの手法を比較し，提案手法の評価を行った．
平均スコアでは提案手法によるGAZEが従来手法のALLを上回り，視線の利用により二人称動作認識の精度が向上することが確認された．
しかしながら，動作種類ごとに認識精度に差があることが確認された．

図\ref{fig:score_action}に示した動作種類ごとのFスコアの比較では，``指差す"や``主張する"といった動作ではGAZEによる認識精度がALLによる認識精度を大きく上回ることが確認された．
これらの動作ではカメラ装着者の視線が動作認識の対象者の手元を追いかけるように動くことが確認されている．
このことから，手元の局所特徴を効果的に選択されたことによりGAZEによる認識精度がALLによる認識精度よりも高くなったと考えられる．
また，``指差す"ではカメラ装着者が指をさした方向に顔向けを行うことで映像に自発的カメラ運動が生まれ，背景動作特徴が盛んに生成されていることが確認された．この背景動作特徴がALLによる認識の際に結果に影響を与えたこともGAZEとALLの認識精度に差が出た要因の一つであると考えられる．
``指差す"の動作映像の例を図\ref{fig:exp_pointing}に示す．

また，``指差す"の動作映像ではGAZEとBOXの間でも認識精度に大きな差が確認され，BOXによる認識精度がGAZEによる認識精度を上回った．
GAZEによる``指差す"の動作認識では視線が手を伸ばした先を追いかけた際にALLよりは少量ながらも，手先の周りの領域の背景の動きが局所特徴に含まれる．
それに対し，BOXでは選択された局所特徴のほとんどが人物領域に由来するものであるため，背景の動きの影響を受けずにGAZEよりも精度が高くなったと考えられる．

\begin{figure}
\begin{center}
    \includegraphics[width=\linewidth]{images/exp_pointing.ai}
    \caption[指差し動作の映像例] {
指差し動作の映像例．
視線位置を黄丸，選択された局所特徴に対応するdense trajectoriesを緑線で可視化した．
カメラ装着者の手の先を視線が追いかけており，その周囲の特徴が選択されていることを確認できる．
        }
    \label{fig:exp_pointing}
\end{center}
\end{figure}

図\ref{fig:result_bad}に示されるような``考える"，``頷く"，``呼ぶ"といった動作ではGAZE, ALL, BOXのいずれも良い認識精度を得ることができなかった．
これらは比較的小さな動きにより構成される動作であることが多く，局所特徴の抽出の段階で動きの特徴を捉えきれなかったことが原因と考えられる．

今回の実験ではほとんどの動作種類において，GAZEによる認識精度はBOXによる動作特徴に達しなかった．
今回作成したデータセットでは，被験者が相手の顔の位置を注視する傾向にあることが確認されている．
それに対して，動作時に特徴的な動きが現れるのは顔から手にかけての領域である．
このことから，動作認識に重要な局所特徴は視線の下側の領域に分布することが推定される．
このように，視線により選択される局所特徴の位置と実際に重要な動作が現れる位置に相違が生じていることが，GAZEによる認識精度がBOXによる認識精度よりも低くなった要因であると考えれる．
このような事実を考慮して局所特徴量の重み付けを求めるためには，視線との距離だけではなく上下左右の位置関係も考慮できるように$f(V)$を構成するという拡張が考えられる．

\newpage

